{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a97330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: keras in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: nltk in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (3.6.5)\n",
      "Requirement already satisfied: spacy-stanza in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (1.41.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (1.21.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: click in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy-stanza) (3.2.1)\n",
      "Requirement already satisfied: stanza<1.4.0,>=1.2.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy-stanza) (1.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.26.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.4.2)\n",
      "Requirement already satisfied: setuptools in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (58.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (21.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.6.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.9.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (8.0.13)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.0.6)\n",
      "Requirement already satisfied: jinja2 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.7.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.6)\n",
      "Requirement already satisfied: torch>=1.3.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from stanza<1.4.0,>=1.2.0->spacy-stanza) (1.10.0)\n",
      "Requirement already satisfied: emoji in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from stanza<1.4.0,>=1.2.0->spacy-stanza) (1.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.0->spacy-stanza) (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/user/code/jupyterenvironment/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras nltk spacy-stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87160a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 16:13:26.447550: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-17 16:13:26.447585: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-12-17 16:13:27.983092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-17 16:13:27.983126: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-17 16:13:27.983144: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (user-HP-ProBook-650-G1): /proc/driver/nvidia/version does not exist\n",
      "2021-12-17 16:13:27.983357: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package stopwords to /home/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7648e371c8be45d48b44af0d9ebb3197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 16:13:30 INFO: Downloading default packages for language: es (Spanish)...\n",
      "2021-12-17 16:13:31 INFO: File exists: /home/user/stanza_resources/es/default.zip.\n",
      "2021-12-17 16:13:36 INFO: Finished downloading models and saved to /home/user/stanza_resources.\n",
      "2021-12-17 16:13:37 INFO: Loading these models for language: es (Spanish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "| lemma     | ancora  |\n",
      "| depparse  | ancora  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2021-12-17 16:13:37 INFO: Use device: cpu\n",
      "2021-12-17 16:13:37 INFO: Loading: tokenize\n",
      "2021-12-17 16:13:37 INFO: Loading: mwt\n",
      "2021-12-17 16:13:37 INFO: Loading: pos\n",
      "2021-12-17 16:13:37 INFO: Loading: lemma\n",
      "2021-12-17 16:13:37 INFO: Loading: depparse\n",
      "2021-12-17 16:13:37 INFO: Loading: ner\n",
      "2021-12-17 16:13:38 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "model = load_model('chatbot_model.h5')\n",
    "# model = load_model('model_checkpoint.h5')\n",
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3c9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = json.loads(open('intents.json').read())\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4dbb440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alimentos_no_sanos', 'alimentos_sanos', 'despedida', 'opciones', 'saludo']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce608dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = tokenize(final_sentence(sentence))\n",
    "    print(sentence_words)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words) \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print(f'found in bag: {w}')\n",
    "    print(np.array(bag))\n",
    "    return(np.array(bag))\n",
    "def predict_class(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    p = bow(sentence, words)\n",
    "    return_list = []\n",
    "    if np.any(p):\n",
    "        res = model.predict(np.array([p]))[0]\n",
    "        ERROR_THRESHOLD = 0.0\n",
    "        results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "        # sort by strength of probability\n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        for r in results:\n",
    "            return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    else:\n",
    "        return_list.append({\"intent\": 'sin respuesta', \"probability\": '90.0'})\n",
    "    print(return_list)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74629ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "def chatbot_response(text):\n",
    "    ints = predict_class(text.lower(), model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d96e9f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clase</th>\n",
       "      <th>alimento</th>\n",
       "      <th>lemma</th>\n",
       "      <th>clase_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>frutoseco</td>\n",
       "      <td>almendra</td>\n",
       "      <td>almendra</td>\n",
       "      <td>frutoseco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>frutoseco</td>\n",
       "      <td>nuez</td>\n",
       "      <td>nuez</td>\n",
       "      <td>frutoseco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>frutoseco</td>\n",
       "      <td>macadamia</td>\n",
       "      <td>macadamia</td>\n",
       "      <td>frutoseco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>frutoseco</td>\n",
       "      <td>habas</td>\n",
       "      <td>haba</td>\n",
       "      <td>frutoseco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>frutoseco</td>\n",
       "      <td>coco</td>\n",
       "      <td>coco</td>\n",
       "      <td>frutoseco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>frutoseco</td>\n",
       "      <td>cacao</td>\n",
       "      <td>cacao</td>\n",
       "      <td>frutoseco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        clase   alimento      lemma clase_lemma\n",
       "45  frutoseco   almendra   almendra   frutoseco\n",
       "46  frutoseco       nuez       nuez   frutoseco\n",
       "47  frutoseco  macadamia  macadamia   frutoseco\n",
       "48  frutoseco      habas       haba   frutoseco\n",
       "49  frutoseco       coco       coco   frutoseco\n",
       "50  frutoseco      cacao      cacao   frutoseco"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsanos[dfsanos.clase_lemma == 'frutoseco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "238fd9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alo']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[{'intent': 'sin respuesta', 'probability': '90.0'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lo siento no te entiendo, recuerda mencionar un solo alimento para asesorarte'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"alo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd07ed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['holar']\n",
      "found in bag: holar\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[{'intent': 'saludo', 'probability': '0.34092775'}, {'intent': 'alimentos_sanos', 'probability': '0.31915215'}, {'intent': 'alimentos_no_sanos', 'probability': '0.17172132'}, {'intent': 'opciones', 'probability': '0.13432778'}, {'intent': 'despedida', 'probability': '0.033870988'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hola, gusto en saludarte soy BOBBY'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"HOLA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc8a5184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adios']\n",
      "found in bag: adios\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[{'intent': 'despedida', 'probability': '0.634675'}, {'intent': 'alimentos_sanos', 'probability': '0.15667336'}, {'intent': 'saludo', 'probability': '0.0878203'}, {'intent': 'opciones', 'probability': '0.06515408'}, {'intent': 'alimentos_no_sanos', 'probability': '0.055677205'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hasta la próxima'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"adios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50554c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['querer', 'comer', 'proteina']\n",
      "found in bag: proteina\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[{'intent': 'alimentos_sanos', 'probability': '0.9154304'}, {'intent': 'alimentos_no_sanos', 'probability': '0.032238916'}, {'intent': 'saludo', 'probability': '0.025358241'}, {'intent': 'despedida', 'probability': '0.018851126'}, {'intent': 'opciones', 'probability': '0.008121277'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'El alimento mencionado es un alimento sano, te ayudará a ser un niño saludable'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"QUIERO COMER ATUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b988327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['querer', 'comer', 'dulce']\n",
      "found in bag: dulce\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[{'intent': 'alimentos_no_sanos', 'probability': '0.37260658'}, {'intent': 'alimentos_sanos', 'probability': '0.28144014'}, {'intent': 'despedida', 'probability': '0.16545594'}, {'intent': 'saludo', 'probability': '0.10278233'}, {'intent': 'opciones', 'probability': '0.07771496'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Estás mencionando un alimento poco saludable, no deberías comer mucho de eso'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"QUIERO COMER DULCES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ba57ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hacer']\n",
      "found in bag: hacer\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[{'intent': 'opciones', 'probability': '0.57060224'}, {'intent': 'alimentos_sanos', 'probability': '0.21452497'}, {'intent': 'alimentos_no_sanos', 'probability': '0.13023484'}, {'intent': 'saludo', 'probability': '0.0574299'}, {'intent': 'despedida', 'probability': '0.027208036'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Puedo ayudarte a verificar si una alimento es sano o no'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"qué haces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bda7db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['querer', 'comer']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[{'intent': 'sin respuesta', 'probability': '90.0'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lo siento no te entiendo, recuerda mencionar un solo alimento para asesorarte'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"QUIERO COMER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be185244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['querer', 'comer', 'frutoseco']\n",
      "found in bag: frutoseco\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[{'intent': 'alimentos_sanos', 'probability': '0.5240166'}, {'intent': 'opciones', 'probability': '0.1868135'}, {'intent': 'saludo', 'probability': '0.12984008'}, {'intent': 'alimentos_no_sanos', 'probability': '0.088256285'}, {'intent': 'despedida', 'probability': '0.071073554'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'El alimento mencionado es un alimento sano, te ayudará a ser un niño saludable'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"QUIERO COMER NUEZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac1f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterenvironment",
   "language": "python",
   "name": "jupyterenvironment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
